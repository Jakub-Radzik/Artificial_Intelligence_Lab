{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importy i pobranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n",
      "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n",
      "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n",
      "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n",
      "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n",
      "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n",
      "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n",
      "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
      "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
      "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
      "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
      "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n",
      "\n",
      "[214 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "glass = pd.read_csv('glass.csv')\n",
    "pd.set_option('display.width', 2137)\n",
    "glass = glass.drop('Id', axis=1)\n",
    "print(glass)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Eksploaracja danych\n",
    "przedstaw podstawowe dane statystyczne i uwagi dotyczące cech i etykiet\n",
    "zbioru danych. (10 punktów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               RI          Na          Mg          Al          Si           K          Ca          Ba          Fe        Type\n",
      "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000\n",
      "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056    8.956963    0.175047    0.057009    2.780374\n",
      "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192    1.423153    0.497219    0.097439    2.103739\n",
      "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000    5.430000    0.000000    0.000000    1.000000\n",
      "25%      1.516522   12.907500    2.115000    1.190000   72.280000    0.122500    8.240000    0.000000    0.000000    1.000000\n",
      "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000    8.600000    0.000000    0.000000    2.000000\n",
      "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000    9.172500    0.000000    0.100000    3.000000\n",
      "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   16.190000    3.150000    0.510000    7.000000\n"
     ]
    }
   ],
   "source": [
    "print(glass.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sumowanie się do 100%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      99.82\n",
      "1      99.89\n",
      "2      99.78\n",
      "3      99.59\n",
      "4      99.83\n",
      "       ...  \n",
      "209    99.95\n",
      "210    99.96\n",
      "211    99.88\n",
      "212    99.98\n",
      "213    99.96\n",
      "Length: 214, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(glass.drop(['RI', 'Type'], axis=1).sum(axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Typy występujące w danych - brakuje typu: 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "print(glass['Type'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Średnie zawartości pierwiastów w danych typach\n",
    "- typ 6: brak: Potasu, Baru i żelaza"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RI         Na        Mg        Al         Si         K         Ca        Ba        Fe\n",
      "Type                                                                                             \n",
      "1     1.518718  13.242286  3.552429  1.163857  72.619143  0.447429   8.797286  0.012714  0.057000\n",
      "2     1.518619  13.111711  3.002105  1.408158  72.598026  0.521053   9.073684  0.050263  0.079737\n",
      "3     1.517964  13.437059  3.543529  1.201176  72.404706  0.406471   8.782941  0.008824  0.057059\n",
      "5     1.518928  12.827692  0.773846  2.033846  72.366154  1.470000  10.123846  0.187692  0.060769\n",
      "6     1.517456  14.646667  1.305556  1.366667  73.206667  0.000000   9.356667  0.000000  0.000000\n",
      "7     1.517116  14.442069  0.538276  2.122759  72.965862  0.325172   8.491379  1.040000  0.013448\n"
     ]
    }
   ],
   "source": [
    "print(glass.groupby('Type').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Korelacje pomiędzy kolumnami"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RI        Na        Mg        Al        Si         K        Ca        Ba        Fe      Type\n",
      "RI    1.000000 -0.191885 -0.122274 -0.407326 -0.542052 -0.289833  0.810403 -0.000386  0.143010 -0.164237\n",
      "Na   -0.191885  1.000000 -0.273732  0.156794 -0.069809 -0.266087 -0.275442  0.326603 -0.241346  0.502898\n",
      "Mg   -0.122274 -0.273732  1.000000 -0.481799 -0.165927  0.005396 -0.443750 -0.492262  0.083060 -0.744993\n",
      "Al   -0.407326  0.156794 -0.481799  1.000000 -0.005524  0.325958 -0.259592  0.479404 -0.074402  0.598829\n",
      "Si   -0.542052 -0.069809 -0.165927 -0.005524  1.000000 -0.193331 -0.208732 -0.102151 -0.094201  0.151565\n",
      "K    -0.289833 -0.266087  0.005396  0.325958 -0.193331  1.000000 -0.317836 -0.042618 -0.007719 -0.010054\n",
      "Ca    0.810403 -0.275442 -0.443750 -0.259592 -0.208732 -0.317836  1.000000 -0.112841  0.124968  0.000952\n",
      "Ba   -0.000386  0.326603 -0.492262  0.479404 -0.102151 -0.042618 -0.112841  1.000000 -0.058692  0.575161\n",
      "Fe    0.143010 -0.241346  0.083060 -0.074402 -0.094201 -0.007719  0.124968 -0.058692  1.000000 -0.188278\n",
      "Type -0.164237  0.502898 -0.744993  0.598829  0.151565 -0.010054  0.000952  0.575161 -0.188278  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(glass.corr())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po analizie\n",
    "- klasyfikator bayesa zakładający niezależność cech może się nie sprawdzić ze względu na to, że jeśli czegoś będzie więcej to czegoś innego musi być mniej - w sumie nie może być więcej niż 100% przecież..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Przygotowanie danych\n",
    "- podziel dane na zestaw uczący i walidacyjny (alternatywnie użyj walidacji krzyżowej),\n",
    "- zbadaj wpływ różnego typu przetworzenia danych na wyniki klasyfikacji (proponowane: normalizacja, standaryzacja, dyskretyzacja, selekcja cech, PCA) - czyli wykonaj porównanie wyników bez przetworzenia danych z rezultatami po ich przetworzeniu, wykorzystując\n",
    "co najmniej 2 metody różnego typu (osobno). (30 punktów)\n",
    "- Bonus – usuń 5% wartości cech i przygotuj dane stosując metody radzenia sobie z brakującymi\n",
    "danymi. (5 punktów)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "usuń 5% cech i uzupełnij wartościami średnimi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n",
      "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n",
      "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n",
      "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n",
      "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n",
      "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n",
      "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n",
      "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
      "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
      "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
      "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
      "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n",
      "\n",
      "[214 rows x 10 columns]\n",
      "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n",
      "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n",
      "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n",
      "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n",
      "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n",
      "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n",
      "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n",
      "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
      "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
      "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
      "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
      "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n",
      "\n",
      "[214 rows x 10 columns]\n",
      "               RI          Na          Mg          Al          Si           K          Ca          Ba          Fe        Type\n",
      "count  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000  203.000000  214.000000\n",
      "mean     1.518338   13.386059    2.695764    1.444828   72.666946    0.504828    8.934236    0.181232    0.058818    2.780374\n",
      "std      0.003082    0.806130    1.439535    0.495182    0.770218    0.665186    1.433944    0.507860    0.099028    2.103739\n",
      "min      1.511150   10.730000    0.000000    0.340000   69.810000    0.000000    5.430000    0.000000    0.000000    1.000000\n",
      "25%      1.516515   12.915000    2.165000    1.190000   72.300000    0.130000    8.225000    0.000000    0.000000    1.000000\n",
      "50%      1.517640   13.290000    3.480000    1.360000   72.810000    0.560000    8.590000    0.000000    0.000000    2.000000\n",
      "75%      1.519130   13.795000    3.595000    1.620000   73.095000    0.610000    9.140000    0.000000    0.100000    3.000000\n",
      "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   16.190000    3.150000    0.510000    7.000000\n",
      "               RI          Na          Mg          Al          Si           K          Ca          Ba          Fe        Type\n",
      "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000\n",
      "mean     1.518338   13.386059    2.695764    1.444828   72.666946    0.504828    8.934236    0.181232    0.058818    2.780374\n",
      "std      0.003001    0.785039    1.401871    0.482226    0.750066    0.647782    1.396427    0.494572    0.096437    2.103739\n",
      "min      1.511150   10.730000    0.000000    0.340000   69.810000    0.000000    5.430000    0.000000    0.000000    1.000000\n",
      "25%      1.516550   12.932500    2.395000    1.192500   72.337500    0.142500    8.247500    0.000000    0.000000    1.000000\n",
      "50%      1.517720   13.330000    3.470000    1.405000   72.765000    0.550000    8.610000    0.000000    0.000000    2.000000\n",
      "75%      1.519050   13.745000    3.587500    1.602500   73.080000    0.600000    9.070000    0.000000    0.090000    3.000000\n",
      "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   16.190000    3.150000    0.510000    7.000000\n"
     ]
    }
   ],
   "source": [
    "glass_copy = glass.copy()\n",
    "for col in glass.columns:\n",
    "    if col == 'Type':\n",
    "        continue\n",
    "    glass_copy[col] = glass_copy[col].sample(frac=0.95, random_state=2137).to_frame().fillna(np.nan)\n",
    "\n",
    "glass_mean_as_nan = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(glass_copy), columns=glass_copy.columns)\n",
    "glass_mean_as_nan['Type'] = glass_mean_as_nan['Type'].astype(int)\n",
    "\n",
    "print(glass_copy)\n",
    "print(glass_mean_as_nan)\n",
    "print(glass_copy.describe())\n",
    "print(glass_mean_as_nan.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "podziel dane na zestaw uczący i walidacyjny (alternatywnie użyj walidacji krzyżowej)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = glass.drop('Type', axis=1)\n",
    "y = glass['Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2137)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "zbadaj wpływ różnego typu przetworzenia danych na wyniki klasyfikacji (proponowane: normalizacja, standaryzacja, dyskretyzacja, selekcja cech, PCA) - czyli wykonaj porównanie wyników bez przetworzenia danych z rezultatami po ich przetworzeniu, wykorzystując co najmniej 2 metody różnego typu (osobno)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standaryzacja\n",
    "- Standaryzacja przybliżyła średnią wartość każdej cechy do 0 oraz odchylenie standardowe do 1 - wartości cech są bardziej porównywalne."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "standarized_X_df = pd.DataFrame(X_train_standardized, columns=X_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dyskretyzacja\n",
    "- Dyskretyzacja podzieliła wartości cech na 100 przedziałów  - uzykujemy lepszą generalizację modelu, ponieważ nie będzie on zbytnio dopasowany do danych treningowych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "# 100 binów, ordinal - zakodowanie jako liczby całkowite, uniform- równomierny podział przedziałów\n",
    "discretizer = KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='uniform')\n",
    "X_train_discretized = discretizer.fit_transform(X_train)\n",
    "X_test_discretized = discretizer.transform(X_test)\n",
    "discretized_X_df = pd.DataFrame(X_train_discretized, columns=X_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selekcja cech\n",
    "- Selekcja cech pozwala na wybrania n najbardziej istotnych cech, dzięki czemu model będzie lepiej radził sobie z nowymi danymi, a także będzie szybciej się uczył. 2 najbardziej istotne cechy to magnez i bar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "X = glass.drop('Type', axis=1)\n",
    "y = glass['Type']\n",
    "X = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(X, y, test_size=0.1,\n",
    "                                                                                        random_state=2137)\n",
    "# dopisuję Mg i Ba po porównaniu z poprzednimi wynikami - Selekcja cech zwraca kolumny bez oznaczeń\n",
    "selected_X_df = pd.DataFrame(X_train_selected, columns=['Mg', 'Ba'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Dane statystyczne po przetworzeniach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1\n",
      "count  214.000000  214.000000\n",
      "mean     2.684533    0.175047\n",
      "std      1.442408    0.497219\n",
      "min      0.000000    0.000000\n",
      "25%      2.115000    0.000000\n",
      "50%      3.480000    0.000000\n",
      "75%      3.600000    0.000000\n",
      "max      4.490000    3.150000\n",
      "               RI          Na          Mg          Al          Si           K          Ca          Ba          Fe\n",
      "count  192.000000  192.000000  192.000000  192.000000  192.000000  192.000000  192.000000  192.000000  192.000000\n",
      "mean     1.518350   13.389896    2.706667    1.448229   72.651354    0.515000    8.924375    0.179271    0.059583\n",
      "std      0.002974    0.829210    1.441589    0.502838    0.780503    0.681026    1.392995    0.509434    0.100031\n",
      "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000    5.430000    0.000000    0.000000\n",
      "25%      1.516528   12.887500    2.165000    1.190000   72.275000    0.137500    8.227500    0.000000    0.000000\n",
      "50%      1.517685   13.260000    3.480000    1.380000   72.800000    0.560000    8.595000    0.000000    0.000000\n",
      "75%      1.519200   13.802500    3.610000    1.632500   73.100000    0.610000    9.142500    0.000000    0.100000\n",
      "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   16.190000    3.150000    0.510000\n",
      "                 RI            Na            Mg            Al            Si             K            Ca            Ba            Fe\n",
      "count  1.920000e+02  1.920000e+02  1.920000e+02  1.920000e+02  1.920000e+02  1.920000e+02  1.920000e+02  1.920000e+02  1.920000e+02\n",
      "mean  -4.833633e-14 -8.141636e-16  8.326673e-17 -4.625929e-18 -1.472896e-14 -9.251859e-18  3.330669e-16 -9.251859e-17 -9.251859e-17\n",
      "std    1.002614e+00  1.002614e+00  1.002614e+00  1.002614e+00  1.002614e+00  1.002614e+00  1.002614e+00  1.002614e+00  1.002614e+00\n",
      "min   -2.427150e+00 -3.216135e+00 -1.882466e+00 -2.309406e+00 -3.649930e+00 -7.581886e-01 -2.515092e+00 -3.528220e-01 -5.972087e-01\n",
      "25%   -6.144116e-01 -6.074572e-01 -3.767251e-01 -5.148861e-01 -4.834548e-01 -5.557596e-01 -5.015789e-01 -3.528220e-01 -5.972087e-01\n",
      "50%   -2.242220e-01 -1.570597e-01  5.378475e-01 -1.360429e-01  1.909466e-01  6.624949e-02 -2.370691e-01 -3.528220e-01 -5.972087e-01\n",
      "75%    2.864796e-01  4.988882e-01  6.282615e-01  3.674197e-01  5.763188e-01  1.398600e-01  1.569964e-01 -3.528220e-01  4.050996e-01\n",
      "max    5.251915e+00  4.824517e+00  1.240295e+00  4.091049e+00  3.543685e+00  8.384241e+00  5.229466e+00  5.846676e+00  4.514564e+00\n",
      "               RI          Na         Mg          Al          Si           K          Ca          Ba          Fe\n",
      "count  192.000000  192.000000  192.00000  192.000000  192.000000  192.000000  192.000000  192.000000  192.000000\n",
      "mean    31.151042   39.505208   59.84375   35.604167   50.244792    7.859375   31.953125    5.593750   11.515625\n",
      "std     13.040938   12.445903   31.90343   15.631207   13.878209   10.881370   12.937744   16.015096   19.418234\n",
      "min      0.000000    0.000000    0.00000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%     23.000000   32.000000   47.50000   28.000000   43.750000    2.000000   25.750000    0.000000    0.000000\n",
      "50%     28.000000   37.500000   77.00000   33.000000   53.000000    9.000000   29.000000    0.000000    0.000000\n",
      "75%     35.000000   46.000000   80.00000   41.250000   58.000000    9.000000   34.000000    0.000000   19.000000\n",
      "max     99.000000   99.000000   99.00000   99.000000   99.000000   99.000000   99.000000   99.000000   99.000000\n",
      "               Mg          Ba\n",
      "count  192.000000  192.000000\n",
      "mean     2.706667    0.179271\n",
      "std      1.441589    0.509434\n",
      "min      0.000000    0.000000\n",
      "25%      2.165000    0.000000\n",
      "50%      3.480000    0.000000\n",
      "75%      3.610000    0.000000\n",
      "max      4.490000    3.150000\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X).describe())\n",
    "print(X_train.describe())\n",
    "print(standarized_X_df.describe())\n",
    "print(discretized_X_df.describe())\n",
    "print(selected_X_df.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Klasyfikacja\n",
    "przetestuj klasyfikatory i zbadaj wpływ na wyniki:\n",
    "- naiwny klasyfikator Bayesa\n",
    "- drzewo decyzjne\n",
    "używając przynajmniej 3 różnych zestawów hiperparametrów. (40 punktów)\n",
    "\n",
    "Bonus – Przetestuj (ze zrozumieniem!) bardziej zaawansowane algorytmy, takie jak Las losowy\n",
    "czy Klasyfikator wektorów nośnych (SVM, z ang. Support Vector Machines). (5 punktów)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naiwny bayes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "smoothings = [0.005, 1e-3, 1e-15]\n",
    "\n",
    "def classificationNB(X_train, X_test):\n",
    "    models = []\n",
    "    for smoothing in smoothings:\n",
    "        nb = GaussianNB(var_smoothing=smoothing)\n",
    "        nb.fit(X_train, y_train)\n",
    "        y_pred = nb.predict(X_test)\n",
    "        models.append((nb, y_pred))\n",
    "    return models\n",
    "\n",
    "fitted_models = classificationNB(X_train, X_test)\n",
    "fitted_models_standarized = classificationNB(X_train_standardized, X_test_standardized)\n",
    "fitted_models_discretized = classificationNB(X_train_discretized, X_test_discretized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drzewo decyzyjne"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "criterion_params = ['gini', 'entropy']\n",
    "max_depth_params = [None, 5, 10]\n",
    "\n",
    "def classificationDT(X_train_p, X_test_p):\n",
    "    models = []\n",
    "    for criterion in criterion_params:\n",
    "        for max_depth in max_depth_params:\n",
    "            tree = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)\n",
    "            tree.fit(X_train_p, y_train)\n",
    "            y_pred = tree.predict(X_test_p)\n",
    "            models.append((tree, y_pred))\n",
    "    return models\n",
    "\n",
    "fitted_models_tree = classificationDT(X_train, X_test)\n",
    "fitted_models_tree_standarized = classificationDT(X_train_standardized, X_test_standardized)\n",
    "fitted_models_tree_discretized = classificationDT(X_train_discretized, X_test_discretized)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ocena modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with original data\n",
      "Native Bayes - smoothing=0.005\n",
      "[[6 0 0 0 0 0]\n",
      " [4 1 0 1 2 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5454545454545454\n",
      "Sensitivity: 0.5208333333333334\n",
      "Precision: 0.4935897435897436\n",
      "F1 score: 0.4200779727095516\n",
      "\n",
      "\n",
      "Native Bayes - smoothing=0.001\n",
      "[[6 0 0 0 0 0]\n",
      " [4 1 0 1 2 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5454545454545454\n",
      "Sensitivity: 0.5208333333333334\n",
      "Precision: 0.4935897435897436\n",
      "F1 score: 0.4200779727095516\n",
      "\n",
      "\n",
      "Native Bayes - smoothing=1e-15\n",
      "[[6 0 0 0 0 0]\n",
      " [4 2 0 2 0 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5909090909090909\n",
      "Sensitivity: 0.5416666666666666\n",
      "Precision: 0.576923076923077\n",
      "F1 score: 0.5052631578947369\n",
      "\n",
      "\n",
      "Naive Bayes with standarized data\n",
      "Native Bayes - smoothing=0.005\n",
      "[[6 0 0 0 0 0]\n",
      " [4 1 0 1 2 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5454545454545454\n",
      "Sensitivity: 0.5208333333333334\n",
      "Precision: 0.4935897435897436\n",
      "F1 score: 0.4200779727095516\n",
      "\n",
      "\n",
      "Native Bayes - smoothing=0.001\n",
      "[[6 0 0 0 0 0]\n",
      " [4 2 0 1 1 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5909090909090909\n",
      "Sensitivity: 0.5416666666666666\n",
      "Precision: 0.5213675213675214\n",
      "F1 score: 0.4719298245614036\n",
      "\n",
      "\n",
      "Native Bayes - smoothing=1e-15\n",
      "[[6 0 0 0 0 0]\n",
      " [4 2 0 2 0 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5909090909090909\n",
      "Sensitivity: 0.5416666666666666\n",
      "Precision: 0.576923076923077\n",
      "F1 score: 0.5052631578947369\n",
      "\n",
      "\n",
      "Naive Bayes with discretized data\n",
      "Native Bayes - smoothing=0.005\n",
      "[[6 0 0 0 0 0]\n",
      " [4 1 0 1 2 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5454545454545454\n",
      "Sensitivity: 0.5208333333333334\n",
      "Precision: 0.4935897435897436\n",
      "F1 score: 0.4200779727095516\n",
      "\n",
      "\n",
      "Native Bayes - smoothing=0.001\n",
      "[[6 0 0 0 0 0]\n",
      " [4 1 0 1 2 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5454545454545454\n",
      "Sensitivity: 0.5208333333333334\n",
      "Precision: 0.4935897435897436\n",
      "F1 score: 0.4200779727095516\n",
      "\n",
      "\n",
      "Native Bayes - smoothing=1e-15\n",
      "[[6 0 0 0 0 0]\n",
      " [4 2 0 1 1 0]\n",
      " [3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 3]]\n",
      "Accuracy: 0.5909090909090909\n",
      "Sensitivity: 0.5416666666666666\n",
      "Precision: 0.5213675213675214\n",
      "F1 score: 0.4719298245614036\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def evaluationNB(title, models):\n",
    "    print(title)\n",
    "    for i, (model, y_pred) in enumerate(models):\n",
    "        print(f'Native Bayes - smoothing={smoothings[i]}')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "        print(f'Sensitivity: {recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "        print(f'Precision: {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "        print(f'F1 score: {f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "        print('\\n')\n",
    "\n",
    "evaluationNB('Naive Bayes with original data', fitted_models)\n",
    "evaluationNB('Naive Bayes with standarized data', fitted_models_standarized)\n",
    "evaluationNB('Naive Bayes with discretized data', fitted_models_discretized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with original data\n",
      "Decision Tree - criterion=gini + max_depth=None\n",
      "[[5 0 1 0 0]\n",
      " [1 5 2 0 0]\n",
      " [1 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.825\n",
      "Precision: 0.8228571428571427\n",
      "F1 score: 0.8076923076923077\n",
      "\n",
      "\n",
      "Decision Tree - criterion=gini + max_depth=5\n",
      "[[6 0 0 0 0]\n",
      " [1 6 1 0 0]\n",
      " [1 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.8636363636363636\n",
      "Sensitivity: 0.8833333333333332\n",
      "Precision: 0.8833333333333332\n",
      "F1 score: 0.8761904761904763\n",
      "\n",
      "\n",
      "Decision Tree - criterion=gini + max_depth=10\n",
      "[[5 0 1 0 0]\n",
      " [0 6 2 0 0]\n",
      " [1 1 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.7833333333333334\n",
      "Precision: 0.7880952380952382\n",
      "F1 score: 0.7838095238095238\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=None\n",
      "[[4 1 1 0 0]\n",
      " [3 4 1 0 0]\n",
      " [1 1 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.6363636363636364\n",
      "Sensitivity: 0.7\n",
      "Precision: 0.7\n",
      "F1 score: 0.6952380952380952\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=5\n",
      "[[5 1 0 0 0]\n",
      " [3 5 0 0 0]\n",
      " [2 0 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7272727272727273\n",
      "Sensitivity: 0.7583333333333334\n",
      "Precision: 0.8666666666666668\n",
      "F1 score: 0.7678571428571429\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=10\n",
      "[[6 0 0 0 0]\n",
      " [1 6 1 0 0]\n",
      " [0 2 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.8181818181818182\n",
      "Sensitivity: 0.8166666666666668\n",
      "Precision: 0.8214285714285715\n",
      "F1 score: 0.8146153846153845\n",
      "\n",
      "\n",
      "Decision Tree with standardized data\n",
      "Decision Tree - criterion=gini + max_depth=None\n",
      "[[5 0 1 0 0]\n",
      " [1 5 2 0 0]\n",
      " [1 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.825\n",
      "Precision: 0.8228571428571427\n",
      "F1 score: 0.8076923076923077\n",
      "\n",
      "\n",
      "Decision Tree - criterion=gini + max_depth=5\n",
      "[[6 0 0 0 0]\n",
      " [1 6 1 0 0]\n",
      " [1 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.8636363636363636\n",
      "Sensitivity: 0.8833333333333332\n",
      "Precision: 0.8833333333333332\n",
      "F1 score: 0.8761904761904763\n",
      "\n",
      "\n",
      "Decision Tree - criterion=gini + max_depth=10\n",
      "[[5 0 1 0 0]\n",
      " [0 6 2 0 0]\n",
      " [1 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.8181818181818182\n",
      "Sensitivity: 0.85\n",
      "Precision: 0.8466666666666667\n",
      "F1 score: 0.8380952380952381\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=None\n",
      "[[6 0 0 0 0]\n",
      " [1 6 1 0 0]\n",
      " [0 2 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.8181818181818182\n",
      "Sensitivity: 0.8166666666666668\n",
      "Precision: 0.8214285714285715\n",
      "F1 score: 0.8146153846153845\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=5\n",
      "[[5 1 0 0 0]\n",
      " [1 6 1 0 0]\n",
      " [2 0 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.7833333333333334\n",
      "Precision: 0.7964285714285715\n",
      "F1 score: 0.7828571428571428\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=10\n",
      "[[6 0 0 0 0]\n",
      " [3 5 0 0 0]\n",
      " [0 2 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.7916666666666666\n",
      "Precision: 0.8761904761904763\n",
      "F1 score: 0.7933333333333333\n",
      "\n",
      "\n",
      "Decision Tree with discretized data\n",
      "Decision Tree - criterion=gini + max_depth=None\n",
      "[[5 0 1 0 0]\n",
      " [0 7 1 0 0]\n",
      " [1 0 1 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.7083333333333334\n",
      "Precision: 0.7583333333333334\n",
      "F1 score: 0.7130952380952381\n",
      "\n",
      "\n",
      "Decision Tree - criterion=gini + max_depth=5\n",
      "[[6 0 0 0 0]\n",
      " [1 6 1 0 0]\n",
      " [1 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.8636363636363636\n",
      "Sensitivity: 0.8833333333333332\n",
      "Precision: 0.8833333333333332\n",
      "F1 score: 0.8761904761904763\n",
      "\n",
      "\n",
      "Decision Tree - criterion=gini + max_depth=10\n",
      "[[4 1 1 0 0]\n",
      " [0 7 1 0 0]\n",
      " [1 0 1 0 1]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.775\n",
      "Precision: 0.7516666666666667\n",
      "F1 score: 0.7585497835497835\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=None\n",
      "[[6 0 0 0 0]\n",
      " [3 5 0 0 0]\n",
      " [0 2 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.7916666666666666\n",
      "Precision: 0.8761904761904763\n",
      "F1 score: 0.7933333333333333\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=5\n",
      "[[5 1 0 0 0]\n",
      " [2 5 1 0 0]\n",
      " [2 0 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7272727272727273\n",
      "Sensitivity: 0.7583333333333334\n",
      "Precision: 0.7777777777777778\n",
      "F1 score: 0.7561904761904762\n",
      "\n",
      "\n",
      "Decision Tree - criterion=entropy + max_depth=10\n",
      "[[5 0 0 0 1]\n",
      " [1 6 1 0 0]\n",
      " [0 2 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 3]]\n",
      "Accuracy: 0.7727272727272727\n",
      "Sensitivity: 0.7833333333333334\n",
      "Precision: 0.7666666666666667\n",
      "F1 score: 0.7680952380952382\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluationDT(title, models):\n",
    "    print(title)\n",
    "    for i, (model, y_pred) in enumerate(models):\n",
    "        print(f'Decision Tree - criterion={criterion_params[i // 3]} + max_depth={max_depth_params[i % 3]}')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "        print(f'Sensitivity: {recall_score(y_test, y_pred, average=\"macro\")}')\n",
    "        print(f'Precision: {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "        print(f'F1 score: {f1_score(y_test, y_pred, average=\"macro\")}')\n",
    "        print('\\n')\n",
    "\n",
    "evaluationDT('Decision Tree with original data', fitted_models_tree)\n",
    "evaluationDT('Decision Tree with standardized data', fitted_models_tree_standarized)\n",
    "evaluationDT('Decision Tree with discretized data', fitted_models_tree_discretized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model         Data      Parameters  Accuracy  Sensitivity  Precision  F1 score\n",
      "10  Decision Tree     Original        gini - 5  0.863636     0.883333   0.883333  0.876190\n",
      "16  Decision Tree  Standarized        gini - 5  0.863636     0.883333   0.883333  0.876190\n",
      "22  Decision Tree  Discretized        gini - 5  0.863636     0.883333   0.883333  0.876190\n",
      "17  Decision Tree  Standarized       gini - 10  0.818182     0.850000   0.846667  0.838095\n",
      "14  Decision Tree     Original    entropy - 10  0.818182     0.816667   0.821429  0.814615\n",
      "18  Decision Tree  Standarized  entropy - None  0.818182     0.816667   0.821429  0.814615\n",
      "9   Decision Tree     Original     gini - None  0.772727     0.825000   0.822857  0.807692\n",
      "15  Decision Tree  Standarized     gini - None  0.772727     0.825000   0.822857  0.807692\n",
      "20  Decision Tree  Standarized    entropy - 10  0.772727     0.791667   0.876190  0.793333\n",
      "24  Decision Tree  Discretized  entropy - None  0.772727     0.791667   0.876190  0.793333\n",
      "19  Decision Tree  Standarized     entropy - 5  0.772727     0.783333   0.796429  0.782857\n",
      "11  Decision Tree     Original       gini - 10  0.772727     0.783333   0.788095  0.783810\n",
      "26  Decision Tree  Discretized    entropy - 10  0.772727     0.783333   0.766667  0.768095\n",
      "23  Decision Tree  Discretized       gini - 10  0.772727     0.775000   0.751667  0.758550\n",
      "21  Decision Tree  Discretized     gini - None  0.772727     0.708333   0.758333  0.713095\n",
      "13  Decision Tree     Original     entropy - 5  0.727273     0.758333   0.866667  0.767857\n",
      "25  Decision Tree  Discretized     entropy - 5  0.727273     0.758333   0.777778  0.756190\n",
      "12  Decision Tree     Original  entropy - None  0.636364     0.700000   0.700000  0.695238\n",
      "2     Naive Bayes     Original             0.0  0.590909     0.541667   0.576923  0.505263\n",
      "5     Naive Bayes  Standarized             0.0  0.590909     0.541667   0.576923  0.505263\n",
      "4     Naive Bayes  Standarized           0.001  0.590909     0.541667   0.521368  0.471930\n",
      "8     Naive Bayes  Discretized             0.0  0.590909     0.541667   0.521368  0.471930\n",
      "0     Naive Bayes     Original           0.005  0.545455     0.520833   0.493590  0.420078\n",
      "1     Naive Bayes     Original           0.001  0.545455     0.520833   0.493590  0.420078\n",
      "3     Naive Bayes  Standarized           0.005  0.545455     0.520833   0.493590  0.420078\n",
      "6     Naive Bayes  Discretized           0.005  0.545455     0.520833   0.493590  0.420078\n",
      "7     Naive Bayes  Discretized           0.001  0.545455     0.520833   0.493590  0.420078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jakubradzik-vazco/Desktop/STUDIA SEM 6/Artificial_Intelligence_Lab/Lista4/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "def appendNB(models, name):\n",
    "    for i, (_, y_pred) in enumerate(models):\n",
    "        data.append(['Naive Bayes', name, smoothings[i], accuracy_score(y_test, y_pred),\n",
    "                     recall_score(y_test, y_pred, average=\"macro\"), precision_score(y_test, y_pred, average=\"macro\"),\n",
    "                     f1_score(y_test, y_pred, average=\"macro\")])\n",
    "\n",
    "def appendDT(models_p, name):\n",
    "    for i, (_, y_pred) in enumerate(models_p):\n",
    "        data.append(['Decision Tree', name, f'{criterion_params[i // 3]} - {max_depth_params[i % 3]}',\n",
    "                     accuracy_score(y_test, y_pred), recall_score(y_test, y_pred, average=\"macro\"),\n",
    "                     precision_score(y_test, y_pred, average=\"macro\"), f1_score(y_test, y_pred, average=\"macro\")])\n",
    "#\n",
    "appendNB(fitted_models, 'Original')\n",
    "appendNB(fitted_models_standarized, 'Standarized')\n",
    "appendNB(fitted_models_discretized, 'Discretized')\n",
    "\n",
    "appendDT(fitted_models_tree, 'Original')\n",
    "appendDT(fitted_models_tree_standarized, 'Standarized')\n",
    "appendDT(fitted_models_tree_discretized, 'Discretized')\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Model', 'Data', 'Parameters', 'Accuracy', 'Sensitivity', 'Precision', 'F1 score'])\n",
    "\n",
    "df.sort_values(by=['Accuracy', 'Sensitivity', 'Precision', 'F1 score'], ascending=False, inplace=True)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}